{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Utility method for YOLO Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "\n",
    "def get_contrast_color(bg_color):\n",
    "    # Calculate the luminance of the background color\n",
    "    # using the formula for luminance under the sRGB Luma (Rec. 709)\n",
    "    luminance = (0.299 * bg_color[0] + 0.587 * bg_color[1] + 0.114 * bg_color[2]) / 255\n",
    "    # Return white if the background is dark; black if the background is light\n",
    "    return (255, 255, 255) if luminance < 0.5 else (0, 0, 0)\n",
    "\n",
    "\n",
    "# Function to generate unique colors for each class ID\n",
    "def get_unique_color(tag):\n",
    "    np.random.seed(tag)  # Seed with tag to get consistent color for the same tag\n",
    "    return [int(x) for x in np.random.randint(0, 255, 3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize YOLO direction prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 992x704 4 clefGs, 2 clefCAltos, 2 clefCTenors, 5 clefFs, 2 clef8s, 37 noteheadBlackOnLines, 43 noteheadBlackInSpaces, 8 noteheadHalfOnLines, 8 noteheadHalfInSpaces, 5 noteheadWholeOnLines, 1 noteheadWholeInSpace, 5 augmentationDots, 4 flag8thUps, 10 flag8thDowns, 2 accidentalNaturals, 3 accidentalSharps, 36 keyFlats, 7 restQuarters, 10 rest8ths, 4 dynamicPs, 2 dynamicMs, 2 dynamicFs, 3 stringsDownBows, 4 stringsUpBows, 13 slurs, 10 beams, 4 dynamicCrescendoHairpins, 10 dynamicDiminuendoHairpins, 12 staffs, 41.1ms\n",
      "1: 992x704 1 brace, 6 clefFs, 2 clef15s, 12 noteheadBlackOnLines, 15 noteheadBlackInSpaces, 2 flag64thUps, 6 flag128thUps, 1 flag64thDown, 1 accidentalSharp, 8 keySharps, 6 restWholes, 1 restHalf, 2 restQuarters, 4 rest8ths, 4 rest16ths, 6 rest32nds, 6 rest64ths, 7 rest128ths, 15 beams, 8 staffs, 41.1ms\n",
      "Speed: 9.8ms preprocess, 41.1ms inference, 77.8ms postprocess per image at shape (1, 3, 992, 704)\n",
      "[✓] Saved: ./yolo_result/lg-5230237-aug-gutenberg1939--page-2.png\n",
      "[✓] Saved: ./yolo_result/lg-16336832-aug-lilyjazz--page-10.png\n"
     ]
    }
   ],
   "source": [
    "# Load the YOLO model\n",
    "model_path = './trained_models/yolov8m_500ep.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Directory containing images\n",
    "source_dir = './sheet_samples/'\n",
    "image_files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Run inference on all images\n",
    "results = model(image_files)\n",
    "\n",
    "# Directory to save annotated images\n",
    "save_directory = './yolo_result'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "for result in results:\n",
    "    img_path = result.path\n",
    "    image = Image.open(result.path).convert(\"RGB\")\n",
    "    # Draw predictions on the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    boxes = result.boxes.data\n",
    "    confs = result.boxes.conf\n",
    "    cls_ids = result.boxes.cls\n",
    "\n",
    "    for box, conf, cls_id in zip(boxes, confs, cls_ids):\n",
    "        x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "        conf = float(conf)\n",
    "        cls_id = int(cls_id)\n",
    "        label = result.names[cls_id]\n",
    "        label_text = f'{label} {conf:.2f}'\n",
    "        font_scale = 2\n",
    "        color = get_unique_color(cls_id)\n",
    "        text_color = get_contrast_color(color)\n",
    "\n",
    "        # Draw bounding box\n",
    "        draw.rectangle([( x1, y1), (x2, y2)], outline='red', width=3)\n",
    "\n",
    "        font_size = 20  # Change this to the desired font size \n",
    "    \n",
    "        # Draw label text in color matching the bounding box\n",
    "        draw.text((x1, y1 - 40), label_text, fill='blue')\n",
    "\n",
    "    save_path = os.path.join(save_directory, os.path.basename(img_path))\n",
    "    image.save(save_path)\n",
    "    print(f\"[✓] Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use Pairwise Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "# Set directory\n",
    "model = YOLO('./trained_models/yolov8m_500ep.pt')\n",
    "source_dir = './sheet_samples/'\n",
    "output_dir = './yolo_pairwise_result/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "# 1. Define parameters for staff line detection\n",
    "gray_threshold = 250\n",
    "kernel_width = 100\n",
    "response_thresh = 10\n",
    "min_black_ratio = 0.5\n",
    "min_gap_between_lines = 4\n",
    "\n",
    "# 2. Detect horizontal staff lines in the input grayscale image\n",
    "def detect_staff_lines_np(img_np):\n",
    "    binary = (img_np < gray_threshold).astype(np.uint8)\n",
    "    kernel = np.ones((1, kernel_width), dtype=np.uint8)\n",
    "    response = convolve(binary, kernel)\n",
    "    candidates = (response > response_thresh).astype(np.uint8)\n",
    "    image_width = img_np.shape[1]\n",
    "    min_black = int(min_black_ratio * image_width)\n",
    "\n",
    "    valid_y = [\n",
    "        y for y in range(binary.shape[0])\n",
    "        if np.max(candidates[y]) > 0 and np.sum(binary[y]) >= min_black\n",
    "    ]\n",
    "\n",
    "    # 3. Remove nearby duplicate lines using a minimum gap threshold\n",
    "    def deduplicate_lines(y_coords, min_gap=4):\n",
    "        y_coords = sorted(y_coords)\n",
    "        deduped = []\n",
    "        for y in y_coords:\n",
    "            if not deduped or abs(y - deduped[-1]) >= min_gap:\n",
    "                deduped.append(y)\n",
    "        return deduped\n",
    "\n",
    "    return deduplicate_lines(valid_y, min_gap_between_lines)\n",
    "\n",
    "# 4. Group every 5 staff lines into a complete staff system\n",
    "def group_staff_lines(y_coords):\n",
    "    y_coords = sorted(y_coords)\n",
    "    groups = []\n",
    "    group = []\n",
    "    for y in y_coords:\n",
    "        group.append(y)\n",
    "        if len(group) == 5:\n",
    "            groups.append(group)\n",
    "            group = []\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x992 1 clefG, 1 clefCTenor, 1 clefF, 9 noteheadBlackOnLines, 10 noteheadBlackInSpaces, 1 noteheadHalfInSpace, 1 noteheadWholeOnLine, 3 augmentationDots, 2 flag8thDowns, 1 accidentalSharp, 6 keyFlats, 5 restWholes, 3 slurs, 4 beams, 2 staffs, 82.2ms\n",
      "Speed: 2.1ms preprocess, 82.2ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 992)\n",
      "\n",
      "0: 224x992 1 clefG, 1 clefCAlto, 8 noteheadBlackOnLines, 11 noteheadBlackInSpaces, 4 noteheadHalfInSpaces, 2 noteheadWholeOnLines, 1 noteheadWholeInSpace, 2 flag8thUps, 2 accidentalSharps, 6 keyFlats, 2 restQuarters, 4 rest8ths, 2 dynamicPs, 1 stringsDownBow, 2 stringsUpBows, 4 slurs, 2 beams, 1 dynamicCrescendoHairpin, 4 dynamicDiminuendoHairpins, 2 staffs, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 992)\n",
      "\n",
      "0: 224x992 2 clefFs, 1 clef8, 14 noteheadBlackOnLines, 15 noteheadBlackInSpaces, 3 noteheadHalfOnLines, 1 noteheadHalfInSpace, 5 augmentationDots, 7 flag8thDowns, 6 keyFlats, 2 restQuarters, 2 rest8ths, 2 dynamicPs, 1 stringsUpBow, 2 slurs, 1 beam, 2 dynamicDiminuendoHairpins, 2 staffs, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 992)\n",
      "\n",
      "0: 224x992 1 clefG, 1 clefCTenor, 6 noteheadBlackOnLines, 4 noteheadBlackInSpaces, 3 noteheadWholeOnLines, 2 augmentationDots, 1 flag8thUp, 6 keyFlats, 5 restWholes, 4 slurs, 3 beams, 2 staffs, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 992)\n",
      "\n",
      "0: 224x992 1 clefG, 1 clefCAlto, 10 noteheadBlackOnLines, 11 noteheadBlackInSpaces, 4 noteheadHalfOnLines, 4 noteheadHalfInSpaces, 1 noteheadWholeOnLine, 2 flag8thUps, 1 accidentalNatural, 6 keyFlats, 2 restQuarters, 4 rest8ths, 1 dynamicM, 1 dynamicF, 1 stringsDownBow, 1 stringsUpBow, 3 slurs, 2 beams, 2 dynamicCrescendoHairpins, 3 dynamicDiminuendoHairpins, 2 staffs, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 992)\n",
      "\n",
      "0: 224x992 2 clefFs, 1 clef8, 16 noteheadBlackOnLines, 16 noteheadBlackInSpaces, 3 noteheadHalfOnLines, 2 augmentationDots, 7 flag8thDowns, 1 accidentalNatural, 6 keyFlats, 1 restQuarter, 2 rest8ths, 1 dynamicM, 1 dynamicF, 1 stringsDownBow, 3 slurs, 1 dynamicCrescendoHairpin, 1 dynamicDiminuendoHairpin, 2 staffs, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 992)\n",
      "[✓] Saved: ./yolo_pairwise_result/lg-5230237-aug-gutenberg1939--page-2.png\n",
      "\n",
      "0: 256x992 1 clefF, 1 clef15, 1 noteheadBlackOnLine, 1 flag64thUp, 1 accidentalSharp, 2 keySharps, 1 restWhole, 1 restQuarter, 1 rest8th, 1 rest16th, 1 rest32nd, 1 rest64th, 2 staffs, 80.8ms\n",
      "Speed: 2.6ms preprocess, 80.8ms inference, 2.1ms postprocess per image at shape (1, 3, 256, 992)\n",
      "\n",
      "0: 448x992 2 clefFs, 2 clef8s, 4 noteheadBlackOnLines, 5 noteheadBlackInSpaces, 2 keySharps, 3 restWholes, 2 staffs, 82.8ms\n",
      "Speed: 4.2ms preprocess, 82.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 992)\n",
      "\n",
      "0: 448x992 2 clefFs, 1 clef15, 2 noteheadBlackOnLines, 6 noteheadBlackInSpaces, 1 noteheadHalfOnLine, 1 noteheadHalfInSpace, 2 flag64thDowns, 3 keySharps, 3 restWholes, 1 rest8th, 2 rest16ths, 2 rest32nds, 3 rest64ths, 8 beams, 3 staffs, 1 ottavaBracket, 12.6ms\n",
      "Speed: 4.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 992)\n",
      "\n",
      "0: 384x992 1 brace, 2 clefFs, 1 clef15, 8 noteheadBlackOnLines, 10 noteheadBlackInSpaces, 1 noteheadDoubleWholeOnLine, 1 flag64thUp, 6 flag128thUps, 3 keySharps, 1 restWhole, 1 restHalf, 1 restQuarter, 3 rest8ths, 1 rest16th, 3 rest32nds, 2 rest64ths, 7 rest128ths, 12 beams, 3 staffs, 80.2ms\n",
      "Speed: 3.3ms preprocess, 80.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 992)\n",
      "[✓] Saved: ./yolo_pairwise_result/lg-16336832-aug-lilyjazz--page-10.png\n"
     ]
    }
   ],
   "source": [
    "# Main loop for processing each image in the source directory\n",
    "for fname in os.listdir(source_dir):\n",
    "    if not fname.endswith(('.png', '.jpg', '.jpeg')): \n",
    "        continue  # Skip non-image files\n",
    "\n",
    "    # 1. Load and prepare the image\n",
    "    img_path = os.path.join(source_dir, fname)\n",
    "    full_img = Image.open(img_path).convert(\"RGB\")\n",
    "    gray = full_img.convert(\"L\")\n",
    "    np_gray = np.array(gray)\n",
    "    draw = ImageDraw.Draw(full_img)\n",
    "\n",
    "    # 2. Detect and group staff lines\n",
    "    staff_lines = detect_staff_lines_np(np_gray)\n",
    "    staff_groups = group_staff_lines(staff_lines)\n",
    "\n",
    "    # 3. Loop through pairs of staff groups (each pair = 10 lines)\n",
    "    for i in range(0, len(staff_groups), 2):\n",
    "        groups_in_pair = staff_groups[i:i+2]\n",
    "        if not groups_in_pair:\n",
    "            continue  # Skip if pair is empty\n",
    "\n",
    "        # 4. Define vertical crop boundaries with margin\n",
    "        all_ys = [y for group in groups_in_pair for y in group]\n",
    "        margin = int(0.25 * (max(all_ys) - min(all_ys)))  # Add 25% margin\n",
    "        y_min = max(0, min(all_ys) - margin)\n",
    "        y_max = min(full_img.height, max(all_ys) + margin)\n",
    "        cropped_img = full_img.crop((0, y_min, full_img.width, y_max))\n",
    "\n",
    "        # 5. Run YOLO inference on the cropped region\n",
    "        results = model(cropped_img)\n",
    "        result = results[0]\n",
    "        boxes = result.boxes.data if result.boxes is not None else []\n",
    "\n",
    "        # 6. Draw each detected bounding box with label\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = [int(x) for x in box[:4]]\n",
    "            cls_id = int(box[5].item()) if len(box) > 5 else -1\n",
    "            label = result.names[cls_id] if cls_id in result.names else 'unknown'\n",
    "            conf = float(box[4])\n",
    "            label_text = f'{label} {conf:.2f}'\n",
    "\n",
    "            # Adjust y-coordinates to match original full image\n",
    "            y1 += y_min\n",
    "            y2 += y_min\n",
    "\n",
    "            # Draw bounding box and label text\n",
    "            draw.rectangle([(x1, y1), (x2, y2)], outline='red', width=2)\n",
    "            draw.text((x1, max(0, y1 - 15)), label_text, fill='blue', font=font)\n",
    "\n",
    "    # 7. Save the fully annotated image\n",
    "    save_path = os.path.join(output_dir, fname)\n",
    "    full_img.save(save_path)\n",
    "    print(f\"[✓] Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare the result of two prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved: ./comparison_visualization/lg-5230237-aug-gutenberg1939--page-2.png\n",
      "[✓] Saved: ./comparison_visualization/lg-16336832-aug-lilyjazz--page-10.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置路径（根据实际路径修改）\n",
    "direct_dir = './yolo_result/'\n",
    "pairwise_dir = './yolo_pairwise_result/'\n",
    "output_dir = './comparison_visualization/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 使用 matplotlib 添加 title 对比显示\n",
    "def save_side_by_side_with_titles(img1_path, img2_path, out_path):\n",
    "    img1 = Image.open(img1_path).convert('RGB')\n",
    "    img2 = Image.open(img2_path).convert('RGB')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(80, 40))\n",
    "    axes[0].imshow(img1)\n",
    "    axes[0].set_title('Direct YOLO', fontsize=30)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(img2)\n",
    "    axes[1].set_title('Pairwise YOLO', fontsize=30)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 遍历图像对比并保存\n",
    "for fname in os.listdir(direct_dir):\n",
    "    if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        continue\n",
    "\n",
    "    img1_path = os.path.join(direct_dir, fname)\n",
    "    img2_path = os.path.join(pairwise_dir, fname)\n",
    "    save_path = os.path.join(output_dir, fname)\n",
    "\n",
    "    if not os.path.exists(img2_path):\n",
    "        print(f\"⚠️ Pairwise version missing: {fname}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        save_side_by_side_with_titles(img1_path, img2_path, save_path)\n",
    "        print(f\"[✓] Saved: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error on {fname}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
