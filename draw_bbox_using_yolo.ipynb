{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 992x704 4 braces, 1 coda, 5 clefGs, 5 clefFs, 98 noteheadBlackOnLines, 72 noteheadBlackInSpaces, 5 noteheadHalfOnLines, 2 noteheadHalfInSpaces, 2 accidentalNaturals, 13 accidentalSharps, 6 keySharps, 2 fermataAboves, 1 restHalf, 32 rest8ths, 46 beams, 6 staffs, 19.3ms\n",
      "1: 992x704 6 clefGs, 2 clefFs, 16 timeSig4s, 34 noteheadBlackOnLines, 35 noteheadBlackInSpaces, 1 noteheadHalfOnLine, 3 flag8thDowns, 7 keyFlats, 6 restWholes, 3 restHalfs, 17 restQuarters, 2 rest8ths, 6 dynamicPs, 15 beams, 1 tie, 8 staffs, 19.3ms\n",
      "Speed: 6.3ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 992, 704)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "\n",
    "\n",
    "# Load the YOLO model\n",
    "model_path = '../YOLOv8x_Symbols.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Directory containing images\n",
    "source_dir = './sample/'\n",
    "image_files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Run inference on all images\n",
    "results = model(image_files)\n",
    "\n",
    "# Directory to save annotated images\n",
    "save_directory = './'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "def get_contrast_color(bg_color):\n",
    "    # Calculate the luminance of the background color\n",
    "    # using the formula for luminance under the sRGB Luma (Rec. 709)\n",
    "    luminance = (0.299 * bg_color[0] + 0.587 * bg_color[1] + 0.114 * bg_color[2]) / 255\n",
    "    # Return white if the background is dark; black if the background is light\n",
    "    return (255, 255, 255) if luminance < 0.5 else (0, 0, 0)\n",
    "\n",
    "\n",
    "# Function to generate unique colors for each class ID\n",
    "def get_unique_color(tag):\n",
    "    np.random.seed(tag)  # Seed with tag to get consistent color for the same tag\n",
    "    return [int(x) for x in np.random.randint(0, 255, 3)]\n",
    "\n",
    "for result in results:\n",
    "    img_path = result.path\n",
    "    image = Image.open(result.path).convert(\"RGB\")\n",
    "    # Draw predictions on the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    boxes = result.boxes.data\n",
    "    confs = result.boxes.conf\n",
    "    cls_ids = result.boxes.cls\n",
    "\n",
    "    for box, conf, cls_id in zip(boxes, confs, cls_ids):\n",
    "        x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "        conf = float(conf)\n",
    "        cls_id = int(cls_id)\n",
    "        label = result.names[cls_id]\n",
    "        label_text = f'{label} {conf:.2f}'\n",
    "        font_scale = 2\n",
    "        color = get_unique_color(cls_id)\n",
    "        text_color = get_contrast_color(color)\n",
    "\n",
    "        # Draw bounding box\n",
    "        draw.rectangle([( x1, y1), (x2, y2)], outline='red', width=3)\n",
    "\n",
    "        font_size = 20  # Change this to the desired font size \n",
    "    \n",
    "        # Draw label text in color matching the bounding box\n",
    "        draw.text((x1, y1 - 40), label_text, fill='blue')\n",
    "\n",
    "    save_path = os.path.join(save_directory, os.path.basename(img_path))\n",
    "    image.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([154.], device='cuda:0')\n",
      "conf: tensor([0.9770], device='cuda:0')\n",
      "data: tensor([[2.3257e+02, 2.0378e+03, 1.8643e+03, 2.1048e+03, 9.7699e-01, 1.5400e+02]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (2772, 1960)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1048.4502, 2071.3003, 1631.7665,   66.9996]], device='cuda:0')\n",
      "xywhn: tensor([[0.5349, 0.7472, 0.8325, 0.0242]], device='cuda:0')\n",
      "xyxy: tensor([[ 232.5669, 2037.8004, 1864.3334, 2104.8000]], device='cuda:0')\n",
      "xyxyn: tensor([[0.1187, 0.7351, 0.9512, 0.7593]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(result[0].boxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
