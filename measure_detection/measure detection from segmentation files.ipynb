{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5bf4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms as T\n",
    "from torch.optim import SGD, Adam, Adadelta\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "import torchvision\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "import random\n",
    "from math import radians, cos, sin\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262b848",
   "metadata": {},
   "source": [
    "### function to draw red bboxes around barlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a20da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path):\n",
    "    # Load the image in OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or path is incorrect\")\n",
    "\n",
    "    # Convert the image from BGR to RGB (OpenCV uses BGR by default)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Define the color range for detection\n",
    "    # Color #00ACC6 in RGB is (0, 172, 198)\n",
    "    lower_bound = np.array([0, 172, 198])  # Lower bound of the color\n",
    "    upper_bound = np.array([0, 172, 198])  # Upper bound of the color\n",
    "\n",
    "    # Create a mask to detect specific color\n",
    "    mask = cv2.inRange(image_rgb, lower_bound, upper_bound)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Convert the image to PIL format for easier drawing\n",
    "    image_pil = Image.fromarray(image_rgb)\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "\n",
    "    # Loop over the contours and draw bounding boxes\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=\"red\", width=2)\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "    image_pil.show()\n",
    "\n",
    "    return image_pil\n",
    "\n",
    "# Usage example\n",
    "image_path = './data/ds2_dense/segmentation/lg-101766503886095953-aug-beethoven--page-4_seg.png'\n",
    "result_image = draw_bounding_boxes(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321b60c",
   "metadata": {},
   "source": [
    "### function to get barline bboxes for all images in a directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "624208bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_for_barlines(image_path):\n",
    "    \"\"\" Analyze an image to find barlines, return a DataFrame with bounding box details. \"\"\"\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or path is incorrect\")\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    lower_bound = np.array([0, 172, 198])  # Lower bound of the color\n",
    "    upper_bound = np.array([0, 172, 198])  # Upper bound of the color\n",
    "\n",
    "    mask = cv2.inRange(image_rgb, lower_bound, upper_bound)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    data = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w < 2 or h < 2:\n",
    "            x = x - 1 if w < 2 else x\n",
    "            y = y - 1 if h < 2 else y\n",
    "            w = max(2, w)\n",
    "            h = max(2, h)\n",
    "        orthogonal_bbox = [float(x), float(y), float(x + w), float(y + h)]\n",
    "\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "\n",
    "        # Add each box to the data list\n",
    "        data.append({\n",
    "            'filename': image_path.split('/')[-1].replace('_seg',''),\n",
    "            'a_bbox': orthogonal_bbox,\n",
    "            'o_bbox': [float(coord) for xs in box.tolist() for coord in xs],\n",
    "            'area': w*h,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee989d2",
   "metadata": {},
   "source": [
    "### code to process an entire directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c66a051f-67c3-4577-8471-3d8789279f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = './data/ds2_dense/segmentation/' \n",
    "# template = pd.DataFrame(columns=['filename','a_bbox','o_bbox','area','width','height','ann_id','label',\n",
    "#                         'padded_bbox','duration','rel_position','duration_mask','rel_position_mask'])\n",
    "# template.to_csv('./data/ds2_dense/barlines.csv')\n",
    "# ann_id = -1\n",
    "# for filename in tqdm(os.listdir(directory)):\n",
    "#     if filename.endswith((\".png\", \".jpg\", \".jpeg\")):  # Check for image file extensions\n",
    "#         file_path = os.path.join(directory, filename)\n",
    "#         annotations = analyze_image_for_barlines(file_path)\n",
    "#         if not annotations.empty:\n",
    "#             annotations['ann_id'] = [ann_id - i for i in range(len(annotations))]\n",
    "#             ann_id -= len(annotations)  # Decrement ann_id for next file\n",
    "#             annotations['label'] = 156\n",
    "#             annotations['padded_bbox'] = annotations['a_bbox']\n",
    "#             annotations['duration'] = -1\n",
    "#             annotations['rel_position'] = 0\n",
    "#             annotations['duration_mask'] = 0\n",
    "#             annotations['rel_position_mask'] = 0\n",
    "#             annotations.to_csv('./data/ds2_dense/barlines.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6827680d-9958-4f08-9a87-f67dcc9706ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 1362/1362 [01:03<00:00, 21.62it/s]\n",
      "100%|██████████████████████████████████████████| 352/352 [00:13<00:00, 26.82it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(json_directory, segmentation_directory, output_directory):\n",
    "    json_files = [f for f in os.listdir(json_directory) if f.endswith('.json')]\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        with open(os.path.join(json_directory, json_file), 'r') as file:\n",
    "            data = json.load(file)\n",
    "            images_df = pd.DataFrame(data['images'])\n",
    "            filenames = images_df['filename'].tolist()\n",
    "\n",
    "        output_csv = json_file.replace('.json', '.csv')\n",
    "        output_path = os.path.join(output_directory, output_csv)\n",
    "\n",
    "        # Prepare an empty DataFrame to collect all barline data\n",
    "        barlines_data = pd.DataFrame(columns=['filename', 'a_bbox', 'o_bbox', 'area', 'width', 'height', 'ann_id',\n",
    "                                              'label', 'padded_bbox', 'duration', 'rel_position', 'duration_mask', \n",
    "                                              'rel_position_mask'])\n",
    "        barlines_data.to_csv(output_path)\n",
    "        \n",
    "        ann_id = -1\n",
    "        # Process each image\n",
    "        for filename in tqdm(filenames):\n",
    "            file_path = os.path.join(segmentation_directory, filename.replace('.png','_seg.png'))\n",
    "            annotations = analyze_image_for_barlines(file_path)\n",
    "            \n",
    "            # take annotation df and merge boxes with identical x coordinates\n",
    "            \n",
    "            if not annotations.empty:\n",
    "                annotations['ann_id'] = [ann_id - i for i in range(len(annotations))]\n",
    "                ann_id -= len(annotations)  # Decrement ann_id for next file\n",
    "                annotations['label'] = 156\n",
    "                annotations['padded_bbox'] = annotations['a_bbox']\n",
    "                annotations['duration'] = -1\n",
    "                annotations['rel_position'] = 0\n",
    "                annotations['duration_mask'] = 0\n",
    "                annotations['rel_position_mask'] = 0\n",
    "                barlines_data = pd.concat([barlines_data, annotations], ignore_index=True)\n",
    "        \n",
    "        # Save all collected barline data to CSV after processing all files\n",
    "        if not barlines_data.empty:\n",
    "            barlines_data.to_csv(output_path, index=False)\n",
    "            \n",
    "# Example usage\n",
    "json_directory = './data/ds2_dense/'\n",
    "segmentation_directory = './data/ds2_dense/segmentation/'\n",
    "output_directory = './data/ds2_dense/'\n",
    "process_dataset(json_directory, segmentation_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a3788a-54cf-463d-942c-a6c163bd8833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169cfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
