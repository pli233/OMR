{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2edb82d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'YOLOv8x_Symbols.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 加载 YOLO 模型\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYOLOv8x_Symbols.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 设置图像路径\u001b[39;00m\n\u001b[32m     10\u001b[39m source_dir = \u001b[33m\"\u001b[39m\u001b[33m./samples/\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:54\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\ultralytics\\engine\\model.py:147\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\ultralytics\\engine\\model.py:289\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    286\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Path(weights).suffix == \u001b[33m\"\u001b[39m\u001b[33m.pt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.args[\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1306\u001b[39m, in \u001b[36mattempt_load_one_weight\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattempt_load_one_weight\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1294\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1295\u001b[39m \u001b[33;03m    Load a single model weights.\u001b[39;00m\n\u001b[32m   1296\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1304\u001b[39m \u001b[33;03m        (tuple): Tuple containing the model and checkpoint.\u001b[39;00m\n\u001b[32m   1305\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1306\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1307\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1308\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).to(device).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1211\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1209\u001b[39m                 ckpt = torch.load(f, pickle_module=safe_pickle)\n\u001b[32m   1210\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m             ckpt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\ultralytics\\utils\\patches.py:115\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    113\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1317\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1321\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1323\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1324\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\serialization.py:659\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    661\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\serialization.py:640\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'YOLOv8x_Symbols.pt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# 加载 YOLO 模型\n",
    "model = YOLO(\"YOLOv8x_Symbols.pt\")\n",
    "\n",
    "# 设置图像路径\n",
    "source_dir = \"./samples/\"\n",
    "image_files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# 定义用于 MIDI 的标签集合\n",
    "note_classes = {\n",
    "    'noteheadBlack', 'noteheadHalf', 'noteheadWhole',\n",
    "    'restQuarter', 'restHalf', 'restWhole',\n",
    "    'noteheadBlackOnLine', 'noteheadBlackInSpace',\n",
    "    'noteheadHalfOnLine', 'noteheadWholeInSpace', 'rest8th'\n",
    "}\n",
    "# staff 也需要保留，用于 pitch 匹配\n",
    "extra_classes = {'staff'}\n",
    "\n",
    "# 推理图像\n",
    "results = model(image_files)\n",
    "\n",
    "# 结果保存路径\n",
    "save_json = \"./samples/midi_notes.json\"\n",
    "output = []\n",
    "\n",
    "for result in results:\n",
    "    img_path = result.path\n",
    "    boxes = result.boxes.data\n",
    "    confs = result.boxes.conf\n",
    "    cls_ids = result.boxes.cls\n",
    "\n",
    "    notes = []\n",
    "    for box, conf, cls_id in zip(boxes, confs, cls_ids):\n",
    "        label = result.names[int(cls_id)]\n",
    "        if label not in note_classes and label not in extra_classes:\n",
    "            continue  # 不是音符也不是五线谱，跳过\n",
    "\n",
    "        x1, y1, x2, y2 = map(float, box[:4])\n",
    "        note_data = {\n",
    "            \"label\": label,\n",
    "            \"confidence\": float(conf),\n",
    "            \"bbox\": [x1, y1, x2, y2],\n",
    "            \"center\": [(x1 + x2) / 2, (y1 + y2) / 2]\n",
    "        }\n",
    "        notes.append(note_data)\n",
    "\n",
    "    output.append({\n",
    "        \"filename\": os.path.basename(img_path),\n",
    "        \"notes\": notes\n",
    "    })\n",
    "\n",
    "# 保存 JSON\n",
    "with open(save_json, 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"🎼 Done! MIDI-relevant predictions saved to {save_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4177ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved visualization: ./samples/visualized/lg-16969821-aug-beethoven--page-1.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def visualize_predictions(json_path, image_dir, save_dir):\n",
    "    # 读取json\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for page in data:\n",
    "        filename = page[\"filename\"]\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❗ Image {filename} not found!\")\n",
    "            continue\n",
    "\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", size=20)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        for note in page[\"notes\"]:\n",
    "            label = note[\"label\"]\n",
    "            conf = note[\"confidence\"]\n",
    "            bbox = note[\"bbox\"]\n",
    "            center = note[\"center\"]\n",
    "\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            cx, cy = center\n",
    "\n",
    "            # 颜色区分\n",
    "            if 'staff' in label:\n",
    "                color = (0, 0, 255)  # 蓝色\n",
    "            elif 'notehead' in label:\n",
    "                color = (0, 255, 0)  # 绿色\n",
    "            elif 'rest' in label:\n",
    "                color = (255, 0, 0)  # 红色\n",
    "            else:\n",
    "                color = (255, 165, 0)  # 橙色其他\n",
    "\n",
    "            # 画框\n",
    "            draw.rectangle([(x1, y1), (x2, y2)], outline=color, width=2)\n",
    "            # 写label\n",
    "            draw.text((x1, y1-20), f\"{label} {conf:.2f}\", fill=color, font=font)\n",
    "            # 标记center\n",
    "            r = 3\n",
    "            draw.ellipse([(cx-r, cy-r), (cx+r, cy+r)], fill=color)\n",
    "\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        img.save(save_path)\n",
    "        print(f\"✅ Saved visualization: {save_path}\")\n",
    "\n",
    "# 使用\n",
    "visualize_predictions(\n",
    "    json_path=\"./samples/midi_notes.json\",\n",
    "    image_dir=\"./samples/\",\n",
    "    save_dir=\"./samples/visualized/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3270bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🖼 Image: lg-16969821-aug-beethoven--page-1.png\n",
      "staff 1: top=784.2, bottom=851.2, center=817.7\n",
      "staff 2: top=1327.3, bottom=1394.5, center=1360.9\n",
      "staff 3: top=1870.0, bottom=1936.6, center=1903.3\n",
      "staff 4: top=2411.9, bottom=2479.2, center=2445.5\n",
      "staff 5: top=2575.8, bottom=2642.9, center=2609.3\n",
      "✅ Saved visual to ./samples/staff_visualization\\staff_lg-16969821-aug-beethoven--page-1.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def visualize_staffs(json_path, image_dir, save_dir=\"./samples/staff_visualization\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for page in data:\n",
    "        filename = page[\"filename\"]\n",
    "        notes = page[\"notes\"]\n",
    "        staff_notes = [n for n in notes if n[\"label\"] == \"staff\"]\n",
    "\n",
    "        # 打开图像\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        print(f\"\\n🖼 Image: {filename}\")\n",
    "        for i, s in enumerate(sorted(staff_notes, key=lambda n: n[\"center\"][1])):\n",
    "            x1, y1, x2, y2 = s[\"bbox\"]\n",
    "            cx, cy = s[\"center\"]\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "            draw.line([(x1, cy), (x2, cy)], fill=\"blue\", width=1)\n",
    "            draw.text((x1, y1 - 10), f\"staff {i+1}\", fill=\"green\")\n",
    "            print(f\"staff {i+1}: top={y1:.1f}, bottom={y2:.1f}, center={cy:.1f}\")\n",
    "\n",
    "        out_path = os.path.join(save_dir, f\"staff_{filename}\")\n",
    "        image.save(out_path)\n",
    "        print(f\"✅ Saved visual to {out_path}\")\n",
    "\n",
    "# 示例使用\n",
    "visualize_staffs(\n",
    "    json_path=\"./samples/midi_notes.json\",\n",
    "    image_dir=\"./samples\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a96cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from mido import Message, MidiFile, MidiTrack, MetaMessage\n",
    "\n",
    "# 音符类型到持续时间（ticks）映射\n",
    "def label_to_duration(label):\n",
    "    duration_map = {\n",
    "        \"noteheadWhole\": 1920,\n",
    "        \"noteheadWholeInSpace\": 1920,\n",
    "        \"noteheadHalf\": 960,\n",
    "        \"noteheadHalfOnLine\": 960,\n",
    "        \"noteheadBlack\": 480,\n",
    "        \"noteheadBlackInSpace\": 480,\n",
    "        \"noteheadBlackOnLine\": 480,\n",
    "        \"restWhole\": 1920,\n",
    "        \"restHalf\": 960,\n",
    "        \"restQuarter\": 480,\n",
    "        \"rest8th\": 240,\n",
    "    }\n",
    "    return duration_map.get(label, 480)\n",
    "\n",
    "# 根据五线谱上边与下边计算 pitch，G4 为中心线，MIDI 编号 67\n",
    "def y_to_midi_pitch(y_center, staff_top, staff_bottom):\n",
    "    spacing = (staff_bottom - staff_top) / 4  # 五线谱有 4 个间隔\n",
    "    center_line = staff_top + 2 * spacing     # 第三条线（中间线）代表 G4\n",
    "    offset = round((center_line - y_center) / (spacing / 2))\n",
    "    return 67 + offset\n",
    "\n",
    "# 从 JSON 转 MIDI\n",
    "def json_to_midi(json_path, midi_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    mid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    track.append(MetaMessage('track_name', name=\"Generated by YOLO-OMR\", time=0))\n",
    "    track.append(MetaMessage('set_tempo', tempo=500000, time=0))  # 120 BPM\n",
    "\n",
    "    for page in data:\n",
    "        notes = page[\"notes\"]\n",
    "        staffs = [n for n in notes if n[\"label\"] == \"staff\"]\n",
    "        events = [n for n in notes if n[\"label\"] != \"staff\"]\n",
    "\n",
    "        # 提取所有 staff 的上下边界，排序便于匹配\n",
    "        staff_ranges = sorted([\n",
    "            (n[\"bbox\"][1], n[\"bbox\"][3]) for n in staffs\n",
    "        ], key=lambda r: (r[0] + r[1]) / 2)\n",
    "\n",
    "        time = 0\n",
    "        for note in sorted(events, key=lambda n: n[\"center\"][0]):\n",
    "            y_center = note[\"center\"][1]\n",
    "            label = note[\"label\"]\n",
    "            duration = label_to_duration(label)\n",
    "\n",
    "            # 找到最近的 staff 范围\n",
    "            staff_top, staff_bottom = min(\n",
    "                staff_ranges, key=lambda r: abs((r[0] + r[1]) / 2 - y_center)\n",
    "            )\n",
    "\n",
    "            if \"notehead\" in label:\n",
    "                pitch = y_to_midi_pitch(y_center, staff_top, staff_bottom)\n",
    "                track.append(Message('note_on', note=pitch, velocity=64, time=time))\n",
    "                track.append(Message('note_off', note=pitch, velocity=64, time=duration))\n",
    "                time = 0  # reset after note\n",
    "            elif \"rest\" in label:\n",
    "                time += duration  # skip ahead\n",
    "\n",
    "    mid.save(midi_path)\n",
    "    print(f\"🎼 MIDI saved to {midi_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd1ce0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data byte must be in range 0..127",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mjson_to_midi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./samples/midi_notes.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmidi_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./samples/output_pitch.mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mjson_to_midi\u001b[39m\u001b[34m(json_path, midi_path)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnotehead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m label:\n\u001b[32m     62\u001b[39m     pitch = y_to_midi_pitch(y_center, staff_top, staff_bottom)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     track.append(\u001b[43mMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnote_on\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpitch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvelocity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     64\u001b[39m     track.append(Message(\u001b[33m'\u001b[39m\u001b[33mnote_off\u001b[39m\u001b[33m'\u001b[39m, note=pitch, velocity=\u001b[32m64\u001b[39m, time=duration))\n\u001b[32m     65\u001b[39m     time = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# reset after note\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\mido\\messages\\messages.py:120\u001b[39m, in \u001b[36mMessage.__init__\u001b[39m\u001b[34m(self, type, skip_checks, **args)\u001b[39m\n\u001b[32m    117\u001b[39m     msgdict[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m] = SysexData(msgdict[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_checks:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[43mcheck_msgdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsgdict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m).update(msgdict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\mido\\messages\\checks.py:107\u001b[39m, in \u001b[36mcheck_msgdict\u001b[39m\u001b[34m(msgdict)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m spec[\u001b[33m'\u001b[39m\u001b[33mattribute_names\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    105\u001b[39m         \u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m message has no attribute \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(spec[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m], name))\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43mcheck_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\mido\\messages\\checks.py:94\u001b[39m, in \u001b[36mcheck_value\u001b[39m\u001b[34m(name, value)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_value\u001b[39m(name, value):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[43m_CHECKS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\23995\\anaconda3\\envs\\pytorch-gpu\\Lib\\site-packages\\mido\\messages\\checks.py:67\u001b[39m, in \u001b[36mcheck_data_byte\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mdata byte must be int\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= value <= \u001b[32m127\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mdata byte must be in range 0..127\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: data byte must be in range 0..127"
     ]
    }
   ],
   "source": [
    "json_to_midi(\n",
    "    json_path=\"./samples/midi_notes.json\",\n",
    "    midi_path=\"./samples/output_pitch.mid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import time\n",
    "\n",
    "midi_file = \"./samples/output_pitch.mid\"\n",
    "pygame.init()\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(midi_file)\n",
    "pygame.mixer.music.play()\n",
    "\n",
    "while pygame.mixer.music.get_busy():\n",
    "    time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db109f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
